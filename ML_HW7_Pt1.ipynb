{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P8syPr5BDDO1",
        "outputId": "6b3b2c35-c08c-4172-8b55-fa7c988786cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 5ms/step - accuracy: 0.3938 - loss: 1.6667 - val_accuracy: 0.6031 - val_loss: 1.1362\n",
            "Epoch 2/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6109 - loss: 1.1207 - val_accuracy: 0.6466 - val_loss: 1.0172\n",
            "Epoch 3/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.6633 - loss: 0.9567 - val_accuracy: 0.6695 - val_loss: 0.9443\n",
            "Epoch 4/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.7000 - loss: 0.8609 - val_accuracy: 0.6797 - val_loss: 0.9370\n",
            "Epoch 5/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7293 - loss: 0.7896 - val_accuracy: 0.6954 - val_loss: 0.8881\n",
            "Epoch 6/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7458 - loss: 0.7233 - val_accuracy: 0.6924 - val_loss: 0.9058\n",
            "Epoch 7/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.6673 - val_accuracy: 0.6919 - val_loss: 0.9380\n",
            "Epoch 8/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.7831 - loss: 0.6222 - val_accuracy: 0.7020 - val_loss: 0.9073\n",
            "Epoch 9/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8009 - loss: 0.5727 - val_accuracy: 0.6977 - val_loss: 0.9269\n",
            "Epoch 10/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8083 - loss: 0.5494 - val_accuracy: 0.7093 - val_loss: 0.9310\n",
            "Epoch 11/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8256 - loss: 0.4962 - val_accuracy: 0.7008 - val_loss: 0.9343\n",
            "Epoch 12/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8345 - loss: 0.4716 - val_accuracy: 0.7097 - val_loss: 0.9393\n",
            "Epoch 13/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8491 - loss: 0.4299 - val_accuracy: 0.6983 - val_loss: 1.0408\n",
            "Epoch 14/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8561 - loss: 0.4072 - val_accuracy: 0.7033 - val_loss: 1.0347\n",
            "Epoch 15/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.8695 - loss: 0.3784 - val_accuracy: 0.6898 - val_loss: 1.1014\n",
            "Epoch 16/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 4ms/step - accuracy: 0.8817 - loss: 0.3440 - val_accuracy: 0.7030 - val_loss: 1.1273\n",
            "Epoch 17/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8868 - loss: 0.3209 - val_accuracy: 0.6958 - val_loss: 1.1591\n",
            "Epoch 18/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.8965 - loss: 0.2938 - val_accuracy: 0.6845 - val_loss: 1.2422\n",
            "Epoch 19/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9000 - loss: 0.2814 - val_accuracy: 0.6953 - val_loss: 1.2635\n",
            "Epoch 20/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9112 - loss: 0.2518 - val_accuracy: 0.6891 - val_loss: 1.3457\n",
            "Epoch 21/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9124 - loss: 0.2457 - val_accuracy: 0.6915 - val_loss: 1.3571\n",
            "Epoch 22/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9202 - loss: 0.2230 - val_accuracy: 0.6886 - val_loss: 1.4287\n",
            "Epoch 23/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9257 - loss: 0.2071 - val_accuracy: 0.6862 - val_loss: 1.5714\n",
            "Epoch 24/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9315 - loss: 0.1919 - val_accuracy: 0.6906 - val_loss: 1.6260\n",
            "Epoch 25/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9372 - loss: 0.1764 - val_accuracy: 0.6916 - val_loss: 1.6706\n",
            "Epoch 26/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9408 - loss: 0.1657 - val_accuracy: 0.6873 - val_loss: 1.7136\n",
            "Epoch 27/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9438 - loss: 0.1590 - val_accuracy: 0.6902 - val_loss: 1.7914\n",
            "Epoch 28/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9434 - loss: 0.1604 - val_accuracy: 0.6837 - val_loss: 1.8776\n",
            "Epoch 29/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9489 - loss: 0.1427 - val_accuracy: 0.6854 - val_loss: 2.0169\n",
            "Epoch 30/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9496 - loss: 0.1349 - val_accuracy: 0.6807 - val_loss: 2.0241\n",
            "Epoch 31/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9525 - loss: 0.1322 - val_accuracy: 0.6764 - val_loss: 2.1723\n",
            "Epoch 32/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9521 - loss: 0.1348 - val_accuracy: 0.6878 - val_loss: 2.1455\n",
            "Epoch 33/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9581 - loss: 0.1182 - val_accuracy: 0.6752 - val_loss: 2.3093\n",
            "Epoch 34/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.9605 - loss: 0.1117 - val_accuracy: 0.6782 - val_loss: 2.2943\n",
            "Epoch 35/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9588 - loss: 0.1151 - val_accuracy: 0.6817 - val_loss: 2.3285\n",
            "Epoch 36/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9629 - loss: 0.1079 - val_accuracy: 0.6790 - val_loss: 2.4033\n",
            "Epoch 37/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9647 - loss: 0.0969 - val_accuracy: 0.6850 - val_loss: 2.4721\n",
            "Epoch 38/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9663 - loss: 0.0953 - val_accuracy: 0.6847 - val_loss: 2.4456\n",
            "Epoch 39/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9642 - loss: 0.0989 - val_accuracy: 0.6830 - val_loss: 2.5018\n",
            "Epoch 40/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9666 - loss: 0.0930 - val_accuracy: 0.6797 - val_loss: 2.5704\n",
            "Epoch 41/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.9681 - loss: 0.0892 - val_accuracy: 0.6779 - val_loss: 2.6365\n",
            "Epoch 42/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9667 - loss: 0.0916 - val_accuracy: 0.6707 - val_loss: 2.7970\n",
            "Epoch 43/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0788 - val_accuracy: 0.6800 - val_loss: 2.7506\n",
            "Epoch 44/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9693 - loss: 0.0884 - val_accuracy: 0.6749 - val_loss: 2.9046\n",
            "Epoch 45/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9703 - loss: 0.0803 - val_accuracy: 0.6740 - val_loss: 2.8747\n",
            "Epoch 46/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0774 - val_accuracy: 0.6791 - val_loss: 2.9058\n",
            "Epoch 47/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9716 - loss: 0.0813 - val_accuracy: 0.6796 - val_loss: 2.9657\n",
            "Epoch 48/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9706 - loss: 0.0834 - val_accuracy: 0.6753 - val_loss: 3.0359\n",
            "Epoch 49/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0827 - val_accuracy: 0.6756 - val_loss: 3.1501\n",
            "Epoch 50/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9715 - loss: 0.0831 - val_accuracy: 0.6825 - val_loss: 3.1397\n",
            "Epoch 51/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9737 - loss: 0.0727 - val_accuracy: 0.6737 - val_loss: 3.3247\n",
            "Epoch 52/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9740 - loss: 0.0747 - val_accuracy: 0.6760 - val_loss: 3.2394\n",
            "Epoch 53/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9748 - loss: 0.0694 - val_accuracy: 0.6776 - val_loss: 3.2987\n",
            "Epoch 54/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9723 - loss: 0.0784 - val_accuracy: 0.6742 - val_loss: 3.4376\n",
            "Epoch 55/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9733 - loss: 0.0795 - val_accuracy: 0.6744 - val_loss: 3.3320\n",
            "Epoch 56/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9777 - loss: 0.0619 - val_accuracy: 0.6770 - val_loss: 3.4014\n",
            "Epoch 57/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9750 - loss: 0.0694 - val_accuracy: 0.6748 - val_loss: 3.4589\n",
            "Epoch 58/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0625 - val_accuracy: 0.6722 - val_loss: 3.4351\n",
            "Epoch 59/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9762 - loss: 0.0706 - val_accuracy: 0.6746 - val_loss: 3.5194\n",
            "Epoch 60/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9814 - loss: 0.0555 - val_accuracy: 0.6720 - val_loss: 3.6850\n",
            "Epoch 61/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0664 - val_accuracy: 0.6751 - val_loss: 3.6575\n",
            "Epoch 62/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9754 - loss: 0.0750 - val_accuracy: 0.6721 - val_loss: 3.6076\n",
            "Epoch 63/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0664 - val_accuracy: 0.6720 - val_loss: 3.7625\n",
            "Epoch 64/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9765 - loss: 0.0688 - val_accuracy: 0.6758 - val_loss: 3.6386\n",
            "Epoch 65/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9788 - loss: 0.0631 - val_accuracy: 0.6730 - val_loss: 3.7578\n",
            "Epoch 66/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9769 - loss: 0.0696 - val_accuracy: 0.6701 - val_loss: 3.7877\n",
            "Epoch 67/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9719 - loss: 0.0804 - val_accuracy: 0.6770 - val_loss: 3.7575\n",
            "Epoch 68/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9785 - loss: 0.0647 - val_accuracy: 0.6765 - val_loss: 3.8646\n",
            "Epoch 69/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9789 - loss: 0.0598 - val_accuracy: 0.6722 - val_loss: 3.8930\n",
            "Epoch 70/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9787 - loss: 0.0650 - val_accuracy: 0.6732 - val_loss: 3.9811\n",
            "Epoch 71/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0620 - val_accuracy: 0.6729 - val_loss: 4.2412\n",
            "Epoch 72/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9783 - loss: 0.0664 - val_accuracy: 0.6791 - val_loss: 3.8937\n",
            "Epoch 73/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9800 - loss: 0.0570 - val_accuracy: 0.6692 - val_loss: 4.0217\n",
            "Epoch 74/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9825 - loss: 0.0542 - val_accuracy: 0.6799 - val_loss: 3.9463\n",
            "Epoch 75/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9823 - loss: 0.0524 - val_accuracy: 0.6728 - val_loss: 4.0434\n",
            "Epoch 76/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0530 - val_accuracy: 0.6775 - val_loss: 4.2187\n",
            "Epoch 77/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9820 - loss: 0.0578 - val_accuracy: 0.6755 - val_loss: 4.0463\n",
            "Epoch 78/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9826 - loss: 0.0560 - val_accuracy: 0.6687 - val_loss: 4.2392\n",
            "Epoch 79/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9797 - loss: 0.0625 - val_accuracy: 0.6692 - val_loss: 4.2271\n",
            "Epoch 80/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9813 - loss: 0.0554 - val_accuracy: 0.6680 - val_loss: 4.3784\n",
            "Epoch 81/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9793 - loss: 0.0643 - val_accuracy: 0.6697 - val_loss: 4.2341\n",
            "Epoch 82/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0578 - val_accuracy: 0.6697 - val_loss: 4.2313\n",
            "Epoch 83/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9802 - loss: 0.0601 - val_accuracy: 0.6662 - val_loss: 4.1945\n",
            "Epoch 84/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9796 - loss: 0.0615 - val_accuracy: 0.6741 - val_loss: 4.2458\n",
            "Epoch 85/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9781 - loss: 0.0649 - val_accuracy: 0.6751 - val_loss: 4.3401\n",
            "Epoch 86/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9827 - loss: 0.0569 - val_accuracy: 0.6706 - val_loss: 4.3515\n",
            "Epoch 87/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0459 - val_accuracy: 0.6705 - val_loss: 4.4492\n",
            "Epoch 88/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9792 - loss: 0.0632 - val_accuracy: 0.6753 - val_loss: 4.3966\n",
            "Epoch 89/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0493 - val_accuracy: 0.6687 - val_loss: 4.2941\n",
            "Epoch 90/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0525 - val_accuracy: 0.6691 - val_loss: 4.5338\n",
            "Epoch 91/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9848 - loss: 0.0455 - val_accuracy: 0.6681 - val_loss: 4.4427\n",
            "Epoch 92/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9817 - loss: 0.0563 - val_accuracy: 0.6766 - val_loss: 4.4087\n",
            "Epoch 93/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9830 - loss: 0.0524 - val_accuracy: 0.6772 - val_loss: 4.4951\n",
            "Epoch 94/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9831 - loss: 0.0530 - val_accuracy: 0.6696 - val_loss: 4.5285\n",
            "Epoch 95/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0406 - val_accuracy: 0.6687 - val_loss: 4.6597\n",
            "Epoch 96/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9828 - loss: 0.0546 - val_accuracy: 0.6738 - val_loss: 4.6602\n",
            "Epoch 97/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9839 - loss: 0.0486 - val_accuracy: 0.6666 - val_loss: 4.8424\n",
            "Epoch 98/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9804 - loss: 0.0627 - val_accuracy: 0.6707 - val_loss: 4.4239\n",
            "Epoch 99/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9846 - loss: 0.0461 - val_accuracy: 0.6757 - val_loss: 4.6606\n",
            "Epoch 100/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9856 - loss: 0.0452 - val_accuracy: 0.6640 - val_loss: 4.7693\n",
            "Epoch 101/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 0.0456 - val_accuracy: 0.6709 - val_loss: 4.7243\n",
            "Epoch 102/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0436 - val_accuracy: 0.6674 - val_loss: 4.8553\n",
            "Epoch 103/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0739 - val_accuracy: 0.6736 - val_loss: 4.7269\n",
            "Epoch 104/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0447 - val_accuracy: 0.6659 - val_loss: 4.8645\n",
            "Epoch 105/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9791 - loss: 0.0666 - val_accuracy: 0.6667 - val_loss: 4.8535\n",
            "Epoch 106/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0434 - val_accuracy: 0.6741 - val_loss: 4.7803\n",
            "Epoch 107/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0524 - val_accuracy: 0.6679 - val_loss: 4.9062\n",
            "Epoch 108/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0508 - val_accuracy: 0.6656 - val_loss: 4.9821\n",
            "Epoch 109/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9822 - loss: 0.0598 - val_accuracy: 0.6710 - val_loss: 4.9832\n",
            "Epoch 110/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9841 - loss: 0.0460 - val_accuracy: 0.6699 - val_loss: 4.8991\n",
            "Epoch 111/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0512 - val_accuracy: 0.6745 - val_loss: 4.9635\n",
            "Epoch 112/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0469 - val_accuracy: 0.6648 - val_loss: 5.0194\n",
            "Epoch 113/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0519 - val_accuracy: 0.6726 - val_loss: 5.1075\n",
            "Epoch 114/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9847 - loss: 0.0472 - val_accuracy: 0.6721 - val_loss: 5.1070\n",
            "Epoch 115/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0413 - val_accuracy: 0.6721 - val_loss: 5.0880\n",
            "Epoch 116/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9863 - loss: 0.0449 - val_accuracy: 0.6713 - val_loss: 5.2121\n",
            "Epoch 117/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0499 - val_accuracy: 0.6703 - val_loss: 5.1974\n",
            "Epoch 118/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0419 - val_accuracy: 0.6687 - val_loss: 5.2179\n",
            "Epoch 119/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9849 - loss: 0.0498 - val_accuracy: 0.6702 - val_loss: 5.0711\n",
            "Epoch 120/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0456 - val_accuracy: 0.6692 - val_loss: 5.2601\n",
            "Epoch 121/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0506 - val_accuracy: 0.6667 - val_loss: 5.1985\n",
            "Epoch 122/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0492 - val_accuracy: 0.6676 - val_loss: 5.2863\n",
            "Epoch 123/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0426 - val_accuracy: 0.6686 - val_loss: 5.2868\n",
            "Epoch 124/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0526 - val_accuracy: 0.6707 - val_loss: 5.3760\n",
            "Epoch 125/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0430 - val_accuracy: 0.6704 - val_loss: 5.3669\n",
            "Epoch 126/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0457 - val_accuracy: 0.6610 - val_loss: 5.3883\n",
            "Epoch 127/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0418 - val_accuracy: 0.6684 - val_loss: 5.4022\n",
            "Epoch 128/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0457 - val_accuracy: 0.6750 - val_loss: 5.3240\n",
            "Epoch 129/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9853 - loss: 0.0470 - val_accuracy: 0.6659 - val_loss: 5.4697\n",
            "Epoch 130/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9854 - loss: 0.0475 - val_accuracy: 0.6728 - val_loss: 5.5089\n",
            "Epoch 131/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9838 - loss: 0.0568 - val_accuracy: 0.6714 - val_loss: 5.5200\n",
            "Epoch 132/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9859 - loss: 0.0484 - val_accuracy: 0.6709 - val_loss: 5.5289\n",
            "Epoch 133/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0406 - val_accuracy: 0.6633 - val_loss: 5.6326\n",
            "Epoch 134/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9845 - loss: 0.0525 - val_accuracy: 0.6715 - val_loss: 5.5516\n",
            "Epoch 135/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0438 - val_accuracy: 0.6691 - val_loss: 5.6481\n",
            "Epoch 136/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0311 - val_accuracy: 0.6696 - val_loss: 5.5449\n",
            "Epoch 137/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9840 - loss: 0.0468 - val_accuracy: 0.6757 - val_loss: 5.6530\n",
            "Epoch 138/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0392 - val_accuracy: 0.6685 - val_loss: 5.6829\n",
            "Epoch 139/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9868 - loss: 0.0422 - val_accuracy: 0.6696 - val_loss: 5.6878\n",
            "Epoch 140/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0462 - val_accuracy: 0.6696 - val_loss: 5.7216\n",
            "Epoch 141/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0438 - val_accuracy: 0.6691 - val_loss: 5.8002\n",
            "Epoch 142/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0427 - val_accuracy: 0.6637 - val_loss: 5.9696\n",
            "Epoch 143/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0460 - val_accuracy: 0.6711 - val_loss: 5.7396\n",
            "Epoch 144/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0296 - val_accuracy: 0.6724 - val_loss: 5.6843\n",
            "Epoch 145/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0435 - val_accuracy: 0.6711 - val_loss: 5.8610\n",
            "Epoch 146/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0513 - val_accuracy: 0.6697 - val_loss: 5.6364\n",
            "Epoch 147/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0352 - val_accuracy: 0.6727 - val_loss: 5.8207\n",
            "Epoch 148/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0382 - val_accuracy: 0.6703 - val_loss: 5.4664\n",
            "Epoch 149/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9866 - loss: 0.0428 - val_accuracy: 0.6670 - val_loss: 5.7458\n",
            "Epoch 150/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0473 - val_accuracy: 0.6702 - val_loss: 5.7197\n",
            "Epoch 151/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0450 - val_accuracy: 0.6677 - val_loss: 5.7137\n",
            "Epoch 152/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0398 - val_accuracy: 0.6686 - val_loss: 5.8923\n",
            "Epoch 153/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9844 - loss: 0.0535 - val_accuracy: 0.6678 - val_loss: 6.0690\n",
            "Epoch 154/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0414 - val_accuracy: 0.6711 - val_loss: 5.9808\n",
            "Epoch 155/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0477 - val_accuracy: 0.6679 - val_loss: 5.9848\n",
            "Epoch 156/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0362 - val_accuracy: 0.6677 - val_loss: 6.1309\n",
            "Epoch 157/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9850 - loss: 0.0552 - val_accuracy: 0.6720 - val_loss: 6.0922\n",
            "Epoch 158/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0358 - val_accuracy: 0.6687 - val_loss: 6.1514\n",
            "Epoch 159/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0407 - val_accuracy: 0.6667 - val_loss: 6.0234\n",
            "Epoch 160/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0365 - val_accuracy: 0.6700 - val_loss: 5.8533\n",
            "Epoch 161/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0441 - val_accuracy: 0.6697 - val_loss: 5.8634\n",
            "Epoch 162/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0348 - val_accuracy: 0.6707 - val_loss: 6.0073\n",
            "Epoch 163/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9871 - loss: 0.0457 - val_accuracy: 0.6659 - val_loss: 6.0797\n",
            "Epoch 164/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0389 - val_accuracy: 0.6682 - val_loss: 6.1006\n",
            "Epoch 165/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0411 - val_accuracy: 0.6732 - val_loss: 6.1502\n",
            "Epoch 166/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0448 - val_accuracy: 0.6672 - val_loss: 6.1954\n",
            "Epoch 167/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0346 - val_accuracy: 0.6526 - val_loss: 6.6459\n",
            "Epoch 168/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9864 - loss: 0.0530 - val_accuracy: 0.6661 - val_loss: 6.3036\n",
            "Epoch 169/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0542 - val_accuracy: 0.6689 - val_loss: 6.3170\n",
            "Epoch 170/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0402 - val_accuracy: 0.6690 - val_loss: 6.3995\n",
            "Epoch 171/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 0.0451 - val_accuracy: 0.6589 - val_loss: 6.4361\n",
            "Epoch 172/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0391 - val_accuracy: 0.6658 - val_loss: 6.1571\n",
            "Epoch 173/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9906 - loss: 0.0322 - val_accuracy: 0.6622 - val_loss: 6.3921\n",
            "Epoch 174/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0435 - val_accuracy: 0.6673 - val_loss: 6.6184\n",
            "Epoch 175/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9858 - loss: 0.0527 - val_accuracy: 0.6741 - val_loss: 6.3564\n",
            "Epoch 176/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9861 - loss: 0.0506 - val_accuracy: 0.6691 - val_loss: 6.3628\n",
            "Epoch 177/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9872 - loss: 0.0531 - val_accuracy: 0.6575 - val_loss: 6.4363\n",
            "Epoch 178/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0372 - val_accuracy: 0.6632 - val_loss: 6.4653\n",
            "Epoch 179/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9888 - loss: 0.0419 - val_accuracy: 0.6602 - val_loss: 6.5012\n",
            "Epoch 180/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9876 - loss: 0.0420 - val_accuracy: 0.6734 - val_loss: 6.3786\n",
            "Epoch 181/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0389 - val_accuracy: 0.6721 - val_loss: 6.4442\n",
            "Epoch 182/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0376 - val_accuracy: 0.6694 - val_loss: 6.4867\n",
            "Epoch 183/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0369 - val_accuracy: 0.6709 - val_loss: 6.6838\n",
            "Epoch 184/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0377 - val_accuracy: 0.6697 - val_loss: 6.5282\n",
            "Epoch 185/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0442 - val_accuracy: 0.6695 - val_loss: 6.8229\n",
            "Epoch 186/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0516 - val_accuracy: 0.6734 - val_loss: 6.7487\n",
            "Epoch 187/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0326 - val_accuracy: 0.6623 - val_loss: 6.8889\n",
            "Epoch 188/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0391 - val_accuracy: 0.6701 - val_loss: 6.5395\n",
            "Epoch 189/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0414 - val_accuracy: 0.6685 - val_loss: 6.5128\n",
            "Epoch 190/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9881 - loss: 0.0417 - val_accuracy: 0.6661 - val_loss: 6.9298\n",
            "Epoch 191/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9860 - loss: 0.0544 - val_accuracy: 0.6644 - val_loss: 6.7738\n",
            "Epoch 192/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9893 - loss: 0.0390 - val_accuracy: 0.6616 - val_loss: 6.9672\n",
            "Epoch 193/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0521 - val_accuracy: 0.6601 - val_loss: 6.8399\n",
            "Epoch 194/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0422 - val_accuracy: 0.6644 - val_loss: 6.9320\n",
            "Epoch 195/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9882 - loss: 0.0422 - val_accuracy: 0.6694 - val_loss: 6.9966\n",
            "Epoch 196/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0450 - val_accuracy: 0.6703 - val_loss: 6.7609\n",
            "Epoch 197/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0421 - val_accuracy: 0.6625 - val_loss: 6.8264\n",
            "Epoch 198/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0441 - val_accuracy: 0.6633 - val_loss: 7.1600\n",
            "Epoch 199/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0359 - val_accuracy: 0.6657 - val_loss: 7.1624\n",
            "Epoch 200/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9870 - loss: 0.0471 - val_accuracy: 0.6652 - val_loss: 7.1051\n",
            "Epoch 201/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0273 - val_accuracy: 0.6632 - val_loss: 7.1086\n",
            "Epoch 202/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9842 - loss: 0.0591 - val_accuracy: 0.6661 - val_loss: 7.1235\n",
            "Epoch 203/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.0377 - val_accuracy: 0.6630 - val_loss: 6.9938\n",
            "Epoch 204/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9891 - loss: 0.0431 - val_accuracy: 0.6623 - val_loss: 7.1491\n",
            "Epoch 205/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0369 - val_accuracy: 0.6627 - val_loss: 7.3112\n",
            "Epoch 206/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0317 - val_accuracy: 0.6667 - val_loss: 7.1403\n",
            "Epoch 207/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0404 - val_accuracy: 0.6627 - val_loss: 7.3058\n",
            "Epoch 208/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0417 - val_accuracy: 0.6655 - val_loss: 6.9201\n",
            "Epoch 209/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0425 - val_accuracy: 0.6716 - val_loss: 7.0532\n",
            "Epoch 210/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0418 - val_accuracy: 0.6678 - val_loss: 7.4538\n",
            "Epoch 211/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9907 - loss: 0.0360 - val_accuracy: 0.6658 - val_loss: 7.3383\n",
            "Epoch 212/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 0.0430 - val_accuracy: 0.6687 - val_loss: 7.3890\n",
            "Epoch 213/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9911 - loss: 0.0340 - val_accuracy: 0.6676 - val_loss: 7.2908\n",
            "Epoch 214/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9878 - loss: 0.0435 - val_accuracy: 0.6654 - val_loss: 7.2592\n",
            "Epoch 215/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0356 - val_accuracy: 0.6655 - val_loss: 7.4144\n",
            "Epoch 216/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0454 - val_accuracy: 0.6611 - val_loss: 7.1463\n",
            "Epoch 217/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0342 - val_accuracy: 0.6683 - val_loss: 7.2831\n",
            "Epoch 218/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0396 - val_accuracy: 0.6600 - val_loss: 7.2215\n",
            "Epoch 219/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0340 - val_accuracy: 0.6606 - val_loss: 7.6588\n",
            "Epoch 220/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9889 - loss: 0.0418 - val_accuracy: 0.6674 - val_loss: 7.3951\n",
            "Epoch 221/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0294 - val_accuracy: 0.6578 - val_loss: 7.7791\n",
            "Epoch 222/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0329 - val_accuracy: 0.6664 - val_loss: 7.5272\n",
            "Epoch 223/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9887 - loss: 0.0444 - val_accuracy: 0.6624 - val_loss: 7.4528\n",
            "Epoch 224/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0464 - val_accuracy: 0.6611 - val_loss: 7.4642\n",
            "Epoch 225/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0373 - val_accuracy: 0.6654 - val_loss: 7.6748\n",
            "Epoch 226/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0468 - val_accuracy: 0.6651 - val_loss: 7.5362\n",
            "Epoch 227/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0348 - val_accuracy: 0.6679 - val_loss: 7.6395\n",
            "Epoch 228/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9885 - loss: 0.0411 - val_accuracy: 0.6670 - val_loss: 7.5508\n",
            "Epoch 229/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0322 - val_accuracy: 0.6646 - val_loss: 7.7235\n",
            "Epoch 230/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 0.0348 - val_accuracy: 0.6607 - val_loss: 7.8380\n",
            "Epoch 231/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0399 - val_accuracy: 0.6582 - val_loss: 7.5739\n",
            "Epoch 232/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0478 - val_accuracy: 0.6659 - val_loss: 7.9028\n",
            "Epoch 233/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9875 - loss: 0.0521 - val_accuracy: 0.6610 - val_loss: 7.9445\n",
            "Epoch 234/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9921 - loss: 0.0313 - val_accuracy: 0.6639 - val_loss: 7.8788\n",
            "Epoch 235/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9869 - loss: 0.0564 - val_accuracy: 0.6667 - val_loss: 7.6798\n",
            "Epoch 236/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0352 - val_accuracy: 0.6693 - val_loss: 7.9617\n",
            "Epoch 237/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9903 - loss: 0.0404 - val_accuracy: 0.6648 - val_loss: 8.0182\n",
            "Epoch 238/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0499 - val_accuracy: 0.6707 - val_loss: 7.9460\n",
            "Epoch 239/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0346 - val_accuracy: 0.6642 - val_loss: 8.1147\n",
            "Epoch 240/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0354 - val_accuracy: 0.6626 - val_loss: 8.0369\n",
            "Epoch 241/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9886 - loss: 0.0502 - val_accuracy: 0.6689 - val_loss: 8.0726\n",
            "Epoch 242/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0301 - val_accuracy: 0.6651 - val_loss: 7.8595\n",
            "Epoch 243/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0345 - val_accuracy: 0.6676 - val_loss: 7.8009\n",
            "Epoch 244/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0371 - val_accuracy: 0.6617 - val_loss: 8.2560\n",
            "Epoch 245/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0494 - val_accuracy: 0.6618 - val_loss: 8.2772\n",
            "Epoch 246/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0403 - val_accuracy: 0.6651 - val_loss: 8.1650\n",
            "Epoch 247/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.0385 - val_accuracy: 0.6672 - val_loss: 8.2358\n",
            "Epoch 248/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0350 - val_accuracy: 0.6672 - val_loss: 8.0994\n",
            "Epoch 249/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0296 - val_accuracy: 0.6722 - val_loss: 8.0605\n",
            "Epoch 250/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9883 - loss: 0.0451 - val_accuracy: 0.6674 - val_loss: 8.2837\n",
            "Epoch 251/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9877 - loss: 0.0541 - val_accuracy: 0.6717 - val_loss: 8.2141\n",
            "Epoch 252/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0350 - val_accuracy: 0.6639 - val_loss: 8.2023\n",
            "Epoch 253/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9900 - loss: 0.0437 - val_accuracy: 0.6672 - val_loss: 8.2991\n",
            "Epoch 254/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0293 - val_accuracy: 0.6585 - val_loss: 8.6869\n",
            "Epoch 255/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9884 - loss: 0.0489 - val_accuracy: 0.6680 - val_loss: 8.4490\n",
            "Epoch 256/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9914 - loss: 0.0346 - val_accuracy: 0.6711 - val_loss: 8.6320\n",
            "Epoch 257/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0376 - val_accuracy: 0.6625 - val_loss: 8.6559\n",
            "Epoch 258/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9904 - loss: 0.0433 - val_accuracy: 0.6644 - val_loss: 8.6450\n",
            "Epoch 259/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0328 - val_accuracy: 0.6641 - val_loss: 8.5659\n",
            "Epoch 260/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9880 - loss: 0.0490 - val_accuracy: 0.6605 - val_loss: 8.6486\n",
            "Epoch 261/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9897 - loss: 0.0448 - val_accuracy: 0.6744 - val_loss: 8.6464\n",
            "Epoch 262/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9896 - loss: 0.0456 - val_accuracy: 0.6685 - val_loss: 8.3694\n",
            "Epoch 263/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9931 - loss: 0.0282 - val_accuracy: 0.6628 - val_loss: 8.6016\n",
            "Epoch 264/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0446 - val_accuracy: 0.6670 - val_loss: 8.6303\n",
            "Epoch 265/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0308 - val_accuracy: 0.6692 - val_loss: 8.6981\n",
            "Epoch 266/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0464 - val_accuracy: 0.6564 - val_loss: 8.8273\n",
            "Epoch 267/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0342 - val_accuracy: 0.6637 - val_loss: 8.5106\n",
            "Epoch 268/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9894 - loss: 0.0445 - val_accuracy: 0.6652 - val_loss: 9.0013\n",
            "Epoch 269/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9912 - loss: 0.0380 - val_accuracy: 0.6677 - val_loss: 8.8822\n",
            "Epoch 270/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.0423 - val_accuracy: 0.6643 - val_loss: 9.0985\n",
            "Epoch 271/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0411 - val_accuracy: 0.6641 - val_loss: 8.9381\n",
            "Epoch 272/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0345 - val_accuracy: 0.6565 - val_loss: 9.1291\n",
            "Epoch 273/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9892 - loss: 0.0461 - val_accuracy: 0.6666 - val_loss: 8.7759\n",
            "Epoch 274/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9918 - loss: 0.0328 - val_accuracy: 0.6639 - val_loss: 8.8375\n",
            "Epoch 275/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9919 - loss: 0.0369 - val_accuracy: 0.6640 - val_loss: 9.1702\n",
            "Epoch 276/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0348 - val_accuracy: 0.6616 - val_loss: 9.0245\n",
            "Epoch 277/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0372 - val_accuracy: 0.6662 - val_loss: 9.3138\n",
            "Epoch 278/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9898 - loss: 0.0463 - val_accuracy: 0.6671 - val_loss: 9.1371\n",
            "Epoch 279/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9901 - loss: 0.0416 - val_accuracy: 0.6664 - val_loss: 9.0238\n",
            "Epoch 280/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9910 - loss: 0.0379 - val_accuracy: 0.6574 - val_loss: 9.3868\n",
            "Epoch 281/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9932 - loss: 0.0295 - val_accuracy: 0.6659 - val_loss: 9.4655\n",
            "Epoch 282/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9906 - loss: 0.0408 - val_accuracy: 0.6642 - val_loss: 9.3418\n",
            "Epoch 283/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0358 - val_accuracy: 0.6631 - val_loss: 9.5456\n",
            "Epoch 284/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0403 - val_accuracy: 0.6677 - val_loss: 9.5350\n",
            "Epoch 285/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 5ms/step - accuracy: 0.9908 - loss: 0.0480 - val_accuracy: 0.6642 - val_loss: 9.3516\n",
            "Epoch 286/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0384 - val_accuracy: 0.6637 - val_loss: 9.5260\n",
            "Epoch 287/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9933 - loss: 0.0276 - val_accuracy: 0.6606 - val_loss: 9.3777\n",
            "Epoch 288/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 0.0474 - val_accuracy: 0.6540 - val_loss: 9.7183\n",
            "Epoch 289/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0420 - val_accuracy: 0.6651 - val_loss: 9.5217\n",
            "Epoch 290/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9925 - loss: 0.0327 - val_accuracy: 0.6623 - val_loss: 9.6548\n",
            "Epoch 291/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 0.0365 - val_accuracy: 0.6603 - val_loss: 9.7659\n",
            "Epoch 292/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9899 - loss: 0.0462 - val_accuracy: 0.6625 - val_loss: 10.0293\n",
            "Epoch 293/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 0.0347 - val_accuracy: 0.6660 - val_loss: 9.8999\n",
            "Epoch 294/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 0.0407 - val_accuracy: 0.6629 - val_loss: 9.7633\n",
            "Epoch 295/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9913 - loss: 0.0390 - val_accuracy: 0.6645 - val_loss: 9.5140\n",
            "Epoch 296/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9905 - loss: 0.0442 - val_accuracy: 0.6660 - val_loss: 9.7348\n",
            "Epoch 297/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9895 - loss: 0.0509 - val_accuracy: 0.6662 - val_loss: 9.6404\n",
            "Epoch 298/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 4ms/step - accuracy: 0.9922 - loss: 0.0329 - val_accuracy: 0.6629 - val_loss: 9.9422\n",
            "Epoch 299/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 4ms/step - accuracy: 0.9909 - loss: 0.0443 - val_accuracy: 0.6637 - val_loss: 9.8101\n",
            "Epoch 300/300\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.9928 - loss: 0.0294 - val_accuracy: 0.6674 - val_loss: 9.6136\n",
            "\n",
            "Basic CNN Training Time: 1917.99 seconds\n",
            "Basic CNN Final Accuracy: 66.74%\n"
          ]
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test = x_test.astype('float32') / 255.0\n",
        "\n",
        "# Part a: Basic CNN\n",
        "def build_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(64, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "basic_cnn = build_cnn()\n",
        "basic_cnn.compile(optimizer='adam',\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the basic CNN (full 300 epochs)\n",
        "start_time = time.time()\n",
        "history_basic = basic_cnn.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=300,\n",
        "    validation_data=(x_test, y_test),\n",
        "    verbose=1\n",
        ")\n",
        "training_time_basic = time.time() - start_time\n",
        "\n",
        "# Results\n",
        "print(\"\\nBasic CNN Training Time: {:.2f} seconds\".format(training_time_basic))\n",
        "print(\"Basic CNN Final Accuracy: {:.2f}%\".format(history_basic.history['val_accuracy'][-1] * 100))\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models, layers\n",
        "from tensorflow.keras.datasets import cifar10\n",
        "\n",
        "# Load CIFAR-10 dataset\n",
        "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.0\n",
        "x_test  = x_test.astype('float32') / 255.0\n",
        "\n",
        "\n",
        "# Build Extended CNN\n",
        "def build_extended_cnn():\n",
        "    model = models.Sequential([\n",
        "        layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Conv2D(128, (3, 3), activation='relu'),   # extra layer\n",
        "        layers.MaxPooling2D((2, 2)),\n",
        "        layers.Flatten(),\n",
        "        layers.Dense(128, activation='relu'),\n",
        "        layers.Dense(10, activation='softmax')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "\n",
        "extended_cnn = build_extended_cnn()\n",
        "extended_cnn.compile(\n",
        "    optimizer='adam',\n",
        "    loss='sparse_categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "class TenEpochLogger(tf.keras.callbacks.Callback):\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            print(f\"Epoch {epoch+1:3d} | \"\n",
        "                  f\"loss={logs['loss']:.4f} | \"\n",
        "                  f\"acc={logs['accuracy']:.4f} | \"\n",
        "                  f\"val_loss={logs['val_loss']:.4f} | \"\n",
        "                  f\"val_acc={logs['val_accuracy']:.4f}\")\n",
        "\n",
        "\n",
        "\n",
        "# Train 300 epochs\n",
        "start_time = time.time()\n",
        "\n",
        "history_extended = extended_cnn.fit(\n",
        "    x_train, y_train,\n",
        "    epochs=300,\n",
        "    validation_data=(x_test, y_test),\n",
        "    callbacks=[TenEpochLogger()],\n",
        "    verbose=0\n",
        ")\n",
        "\n",
        "training_time_extended = time.time() - start_time\n",
        "\n",
        "print(\"\\nExtended CNN Training Time: {:.2f} seconds\".format(training_time_extended))\n",
        "print(\"Extended CNN Final Accuracy: {:.2f}%\".format(history_extended.history['val_accuracy'][-1] * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P7ZrsBCadnJA",
        "outputId": "d8c4e165-2dfc-4d6d-8216-95326b8ddef0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "\u001b[1m170498071/170498071\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 0us/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/layers/convolutional/base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  10 | loss=0.4757 | acc=0.8325 | val_loss=0.8766 | val_acc=0.7173\n",
            "Epoch  20 | loss=0.2037 | acc=0.9269 | val_loss=1.3831 | val_acc=0.7125\n",
            "Epoch  30 | loss=0.1408 | acc=0.9510 | val_loss=1.9045 | val_acc=0.7156\n",
            "Epoch  40 | loss=0.1133 | acc=0.9612 | val_loss=2.3574 | val_acc=0.6994\n",
            "Epoch  50 | loss=0.0893 | acc=0.9700 | val_loss=2.6946 | val_acc=0.7039\n",
            "Epoch  60 | loss=0.0845 | acc=0.9730 | val_loss=2.8541 | val_acc=0.6959\n",
            "Epoch  70 | loss=0.0786 | acc=0.9753 | val_loss=2.9954 | val_acc=0.7062\n",
            "Epoch  80 | loss=0.0834 | acc=0.9755 | val_loss=3.2501 | val_acc=0.7003\n",
            "Epoch  90 | loss=0.0761 | acc=0.9781 | val_loss=3.4155 | val_acc=0.6982\n",
            "Epoch 100 | loss=0.0680 | acc=0.9802 | val_loss=3.5929 | val_acc=0.7029\n",
            "Epoch 110 | loss=0.0701 | acc=0.9799 | val_loss=3.8214 | val_acc=0.7013\n",
            "Epoch 120 | loss=0.0858 | acc=0.9775 | val_loss=4.1455 | val_acc=0.7016\n",
            "Epoch 130 | loss=0.0571 | acc=0.9840 | val_loss=4.3207 | val_acc=0.6947\n",
            "Epoch 140 | loss=0.0710 | acc=0.9817 | val_loss=4.7561 | val_acc=0.6893\n",
            "Epoch 150 | loss=0.0743 | acc=0.9818 | val_loss=4.9757 | val_acc=0.7028\n",
            "Epoch 160 | loss=0.0645 | acc=0.9844 | val_loss=5.1233 | val_acc=0.6910\n",
            "Epoch 170 | loss=0.0850 | acc=0.9818 | val_loss=5.0839 | val_acc=0.7029\n",
            "Epoch 180 | loss=0.0750 | acc=0.9834 | val_loss=5.5264 | val_acc=0.6988\n",
            "Epoch 190 | loss=0.0780 | acc=0.9837 | val_loss=5.7160 | val_acc=0.6929\n",
            "Epoch 200 | loss=0.0785 | acc=0.9839 | val_loss=6.2574 | val_acc=0.6901\n",
            "Epoch 210 | loss=0.0685 | acc=0.9855 | val_loss=6.4704 | val_acc=0.6935\n",
            "Epoch 220 | loss=0.0772 | acc=0.9846 | val_loss=6.6974 | val_acc=0.7021\n",
            "Epoch 230 | loss=0.0717 | acc=0.9866 | val_loss=7.0541 | val_acc=0.6994\n",
            "Epoch 240 | loss=0.0761 | acc=0.9858 | val_loss=7.6259 | val_acc=0.6932\n",
            "Epoch 250 | loss=0.0811 | acc=0.9861 | val_loss=7.9784 | val_acc=0.6954\n",
            "Epoch 260 | loss=0.0918 | acc=0.9855 | val_loss=8.6012 | val_acc=0.6892\n",
            "Epoch 270 | loss=0.0789 | acc=0.9871 | val_loss=8.3878 | val_acc=0.6999\n",
            "Epoch 280 | loss=0.0934 | acc=0.9856 | val_loss=8.7517 | val_acc=0.6986\n",
            "Epoch 290 | loss=0.1102 | acc=0.9837 | val_loss=10.2609 | val_acc=0.6859\n",
            "Epoch 300 | loss=0.0866 | acc=0.9875 | val_loss=10.0573 | val_acc=0.6939\n",
            "\n",
            "Extended CNN Training Time: 1718.30 seconds\n",
            "Extended CNN Final Accuracy: 69.39%\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}